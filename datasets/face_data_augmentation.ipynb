{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b008228",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34f4a154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6.]), tensor([113, 439, 129,  65, 266, 243]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# Data distribution over classes\n",
    "images = torch.load(\"../diffae/images.pt\")\n",
    "y = torch.load(\"../../GS_data/gender_diffae.pt\")\n",
    "cf = torch.load(\"../../GS_data/skincolor_diffae.pt\")\n",
    "torch.unique(cf, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42b8df96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1255])\n"
     ]
    }
   ],
   "source": [
    "images.shape\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9910ac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "i_flipped = torchvision.transforms.functional.hflip(images)\n",
    "i_jitter = torchvision.transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3)((images + 1) / 2) * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49744664",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_images = torch.cat((images, i_flipped, i_jitter), dim=0)\n",
    "new_y = torch.cat((y, y, y), dim=0)\n",
    "new_cf = torch.cat((cf, cf, cf), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8667d4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0., 1.]), tensor([162, 177]))\n",
      "(tensor([0., 1.]), tensor([792, 525]))\n",
      "(tensor([0., 1.]), tensor([204, 183]))\n",
      "(tensor([0., 1.]), tensor([ 87, 108]))\n",
      "(tensor([0., 1.]), tensor([381, 417]))\n",
      "(tensor([0., 1.]), tensor([456, 273]))\n",
      "(tensor([0., 1.]), tensor([87, 87]))\n",
      "(tensor([0., 1.]), tensor([87, 87]))\n",
      "(tensor([0., 1.]), tensor([87, 87]))\n",
      "(tensor([0., 1.]), tensor([87, 87]))\n",
      "(tensor([0., 1.]), tensor([87, 87]))\n",
      "(tensor([0., 1.]), tensor([87, 87]))\n",
      "(tensor([0., 1.]), tensor([70, 70]))\n",
      "(tensor([0., 1.]), tensor([70, 70]))\n",
      "(tensor([0., 1.]), tensor([70, 70]))\n",
      "(tensor([0., 1.]), tensor([70, 70]))\n",
      "(tensor([0., 1.]), tensor([70, 70]))\n",
      "(tensor([0., 1.]), tensor([70, 70]))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(torch.unique(new_y[new_cf == 1], return_counts=True))\n",
    "print(torch.unique(new_y[new_cf == 2], return_counts=True))\n",
    "print(torch.unique(new_y[new_cf == 3], return_counts=True))\n",
    "print(torch.unique(new_y[new_cf == 4], return_counts=True))\n",
    "print(torch.unique(new_y[new_cf == 5], return_counts=True))\n",
    "print(torch.unique(new_y[new_cf == 6], return_counts=True))\n",
    "\n",
    "\n",
    "idxs = torch.arange(new_images.shape[0])\n",
    "images_1_idxs_new = idxs[torch.logical_and(new_cf == 1, new_y == 0)][:87]\n",
    "images_2_idxs_new = idxs[torch.logical_and(new_cf == 2, new_y == 0)][:87]\n",
    "images_3_idxs_new = idxs[torch.logical_and(new_cf == 3, new_y == 0)][:87]\n",
    "images_4_idxs_new = idxs[torch.logical_and(new_cf == 4, new_y == 0)][:87]\n",
    "images_5_idxs_new = idxs[torch.logical_and(new_cf == 5, new_y == 0)][:87]\n",
    "images_6_idxs_new = idxs[torch.logical_and(new_cf == 6, new_y == 0)][:87]\n",
    "\n",
    "images_1f_idxs_new = idxs[torch.logical_and(new_cf == 1, new_y == 1)][:87]\n",
    "images_2f_idxs_new = idxs[torch.logical_and(new_cf == 2, new_y == 1)][:87]\n",
    "images_3f_idxs_new = idxs[torch.logical_and(new_cf == 3, new_y == 1)][:87]\n",
    "images_4f_idxs_new = idxs[torch.logical_and(new_cf == 4, new_y == 1)][:87]\n",
    "images_5f_idxs_new = idxs[torch.logical_and(new_cf == 5, new_y == 1)][:87]\n",
    "images_6f_idxs_new = idxs[torch.logical_and(new_cf == 6, new_y == 1)][:87]\n",
    "\n",
    "final_images = new_images[torch.cat(\n",
    "    (images_1_idxs_new,\n",
    "    images_2_idxs_new,\n",
    "    images_3_idxs_new,\n",
    "    images_4_idxs_new,\n",
    "    images_5_idxs_new,\n",
    "    images_6_idxs_new,\n",
    "    images_1f_idxs_new,\n",
    "    images_2f_idxs_new,\n",
    "    images_3f_idxs_new,\n",
    "    images_4f_idxs_new,\n",
    "    images_5f_idxs_new,\n",
    "    images_6f_idxs_new,))]\n",
    "final_y = new_y[torch.cat((\n",
    "    images_1_idxs_new,\n",
    "    images_2_idxs_new,\n",
    "    images_3_idxs_new,\n",
    "    images_4_idxs_new,\n",
    "    images_5_idxs_new,\n",
    "    images_6_idxs_new,\n",
    "    images_1f_idxs_new,\n",
    "    images_2f_idxs_new,\n",
    "    images_3f_idxs_new,\n",
    "    images_4f_idxs_new,\n",
    "    images_5f_idxs_new,\n",
    "    images_6f_idxs_new,))]\n",
    "final_cf = new_cf[torch.cat((\n",
    "    images_1_idxs_new,\n",
    "    images_2_idxs_new,\n",
    "    images_3_idxs_new,\n",
    "    images_4_idxs_new,\n",
    "    images_5_idxs_new,\n",
    "    images_6_idxs_new,\n",
    "    images_1f_idxs_new,\n",
    "    images_2f_idxs_new,\n",
    "    images_3f_idxs_new,\n",
    "    images_4f_idxs_new,\n",
    "    images_5f_idxs_new,\n",
    "    images_6f_idxs_new,))]\n",
    "\n",
    "print(torch.unique(final_y[final_cf == 1], return_counts=True))\n",
    "print(torch.unique(final_y[final_cf == 2], return_counts=True))\n",
    "print(torch.unique(final_y[final_cf == 3], return_counts=True))\n",
    "print(torch.unique(final_y[final_cf == 4], return_counts=True))\n",
    "print(torch.unique(final_y[final_cf == 5], return_counts=True))\n",
    "print(torch.unique(final_y[final_cf == 6], return_counts=True))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test, cf_train, cf_test = train_test_split(final_images, final_y, final_cf,\n",
    "                                                                       stratify=final_y * 8 + final_cf,\n",
    "                                                                       test_size=0.195)\n",
    "\n",
    "torch.save(X_train, \"face/balanced/X_train.pt\")\n",
    "torch.save(X_test, \"face/balanced/X_test.pt\")\n",
    "torch.save(y_train, \"face/balanced/y_train.pt\")\n",
    "torch.save(y_test, \"face/balanced/y_test.pt\")\n",
    "torch.save(cf_train, \"face/balanced/cf_train.pt\")\n",
    "torch.save(cf_test, \"face/balanced/cf_test.pt\")\n",
    "\n",
    "\n",
    "print(torch.unique(y_train[cf_train == 1], return_counts=True))\n",
    "print(torch.unique(y_train[cf_train == 2], return_counts=True))\n",
    "print(torch.unique(y_train[cf_train == 3], return_counts=True))\n",
    "print(torch.unique(y_train[cf_train == 4], return_counts=True))\n",
    "print(torch.unique(y_train[cf_train == 5], return_counts=True))\n",
    "print(torch.unique(y_train[cf_train == 6], return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f3a60c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
